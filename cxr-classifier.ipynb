{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import required libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T11:26:43.366458Z","iopub.execute_input":"2022-01-17T11:26:43.367229Z","iopub.status.idle":"2022-01-17T11:26:53.253523Z","shell.execute_reply.started":"2022-01-17T11:26:43.367125Z","shell.execute_reply":"2022-01-17T11:26:53.252628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport PIL\nimport time\nimport timm\nimport math\nimport copy\nimport torch\nimport torchvision\nimport numpy as np\n%matplotlib inline\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nfrom PIL import Image\nimport itertools\nfrom pathlib import Path\nfrom copy import deepcopy\nfrom sklearn import metrics\nimport torch.optim as optim\nfrom torchvision import models\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.optim import lr_scheduler\nfrom timm.models.layers.activations import *\n%config InlineBackend.figure_format = 'retina'\nfrom collections import OrderedDict, defaultdict\nfrom torchvision import transforms, models, datasets\nfrom torch.utils.data.sampler import SubsetRandomSampler\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nfrom timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:48:31.470286Z","iopub.execute_input":"2022-01-17T11:48:31.470559Z","iopub.status.idle":"2022-01-17T11:48:32.833893Z","shell.execute_reply.started":"2022-01-17T11:48:31.470529Z","shell.execute_reply":"2022-01-17T11:48:32.83309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preparation","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nbatch_size = 32\nnum_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:51:56.305639Z","iopub.execute_input":"2022-01-17T11:51:56.306315Z","iopub.status.idle":"2022-01-17T11:51:56.310666Z","shell.execute_reply.started":"2022-01-17T11:51:56.306271Z","shell.execute_reply":"2022-01-17T11:51:56.309494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '/kaggle/input/chest-xray-classification'\ndata_transforms = {\n    'train':transforms.Compose([\n        transforms.RandomRotation(30),\n#         transforms.ColorJitter(brightness=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0.6, 1.4]),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'test':transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:51:57.573671Z","iopub.execute_input":"2022-01-17T11:51:57.574163Z","iopub.status.idle":"2022-01-17T11:51:57.581272Z","shell.execute_reply.started":"2022-01-17T11:51:57.574125Z","shell.execute_reply":"2022-01-17T11:51:57.580601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_datasets = {x : datasets.ImageFolder(os.path.join(root_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\ndata_loader = {x : torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size if x!='test' else 2, shuffle=True, num_workers=2, pin_memory=True) for x in ['train', 'val', 'test']}\ndataset_sizes = {x : len(image_datasets[x]) for x in ['train', 'val', 'test']}\nclass_names = image_datasets['train'].classes","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:51:59.304727Z","iopub.execute_input":"2022-01-17T11:51:59.305706Z","iopub.status.idle":"2022-01-17T11:52:01.684502Z","shell.execute_reply.started":"2022-01-17T11:51:59.305652Z","shell.execute_reply":"2022-01-17T11:52:01.683734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_sizes)\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:01.894055Z","iopub.execute_input":"2022-01-17T11:52:01.894328Z","iopub.status.idle":"2022-01-17T11:52:01.899017Z","shell.execute_reply.started":"2022-01-17T11:52:01.894295Z","shell.execute_reply":"2022-01-17T11:52:01.898036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\nmodel.head","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:05.533877Z","iopub.execute_input":"2022-01-17T11:52:05.534504Z","iopub.status.idle":"2022-01-17T11:52:07.363208Z","shell.execute_reply.started":"2022-01-17T11:52:05.534464Z","shell.execute_reply":"2022-01-17T11:52:07.36248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\nhead = nn.Sequential(OrderedDict([\n    ('fc1', nn.Linear(1024, 512)),\n    ('relu1', nn.ReLU()),\n    ('fc2', nn.Linear(512, 256)),\n    ('relu2', nn.ReLU()),\n    ('fc3', nn.Linear(256, 5))\n]))\nmodel.head = head\nmodel = model.to(device)\n\nfor params in model.parameters():\n    params.requires_grad = True\n    \ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(count_params(model))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:07.36472Z","iopub.execute_input":"2022-01-17T11:52:07.364925Z","iopub.status.idle":"2022-01-17T11:52:07.483829Z","shell.execute_reply.started":"2022-01-17T11:52:07.364901Z","shell.execute_reply":"2022-01-17T11:52:07.483036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training","metadata":{}},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=7)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:13.287089Z","iopub.execute_input":"2022-01-17T11:52:13.287371Z","iopub.status.idle":"2022-01-17T11:52:13.295141Z","shell.execute_reply.started":"2022-01-17T11:52:13.28734Z","shell.execute_reply":"2022-01-17T11:52:13.294106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs , path='model.path'):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = math.inf\n    best_acc = 0.\n    \n    for epoch in range(num_epochs):\n        since_e = time.time()\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            \n            running_loss = 0.0\n            running_correct = 0\n            \n            for i, (inputs, labels) in tqdm(enumerate(data_loader[phase])):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                if i%1000==999:\n                    print(f\"[{epoch+1}, {i} loss: {running_loss/(i*inputs.size(0)):.4f}]\")\n                \n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase=='train':\n                        loss.backward()\n                        optimizer.step()\n                \n                running_loss += loss.item()*inputs.size(0)\n                running_correct += torch.sum(preds==labels.data)\n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_correct / dataset_sizes[phase]\n            print('{} loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val':\n                scheduler.step(epoch_acc)\n            if phase == 'val' and epoch_acc > best_acc:\n                print(f'New acc: {epoch_acc:.4f}, previous acc: {best_acc:.4f}')\n                best_loss = epoch_loss\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), path)\n        time_e = time.time() - since_e\n        print(f'Training epoch {epoch+1} complete in: {time_e//60:.0f}m {time_e%60:.0f}s')\n    time_elapsed = time.time()-since\n    print('Training complete in: {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed%60))\n    print('Best val acc: {:.4f} Best val loss: {:.4f}'.format(best_acc, best_loss))\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:18.146967Z","iopub.execute_input":"2022-01-17T11:52:18.147217Z","iopub.status.idle":"2022-01-17T11:52:18.161164Z","shell.execute_reply.started":"2022-01-17T11:52:18.14719Z","shell.execute_reply":"2022-01-17T11:52:18.16047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, criterion, optimizer, scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:52:18.646276Z","iopub.execute_input":"2022-01-17T11:52:18.647019Z","iopub.status.idle":"2022-01-17T11:52:21.862739Z","shell.execute_reply.started":"2022-01-17T11:52:18.646979Z","shell.execute_reply":"2022-01-17T11:52:21.861573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Prediction on Test set","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:49:23.515404Z","iopub.execute_input":"2022-01-17T11:49:23.516125Z","iopub.status.idle":"2022-01-17T11:49:23.525082Z","shell.execute_reply.started":"2022-01-17T11:49:23.516085Z","shell.execute_reply":"2022-01-17T11:49:23.523791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\nhead = nn.Sequential(OrderedDict([\n    ('fc1', nn.Linear(1024, 512)),\n    ('relu1', nn.ReLU()),\n    ('fc2', nn.Linear(512, 256)),\n    ('relu2', nn.ReLU()),\n    ('fc3', nn.Linear(256, 5))\n]))\nmodel.head = head\nmodel = model.to(device)\n\nmodel.load_state_dict(torch.load('./model.path'))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:49:27.866222Z","iopub.execute_input":"2022-01-17T11:49:27.866817Z","iopub.status.idle":"2022-01-17T11:49:30.035359Z","shell.execute_reply.started":"2022-01-17T11:49:27.866774Z","shell.execute_reply":"2022-01-17T11:49:30.03459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"since = time.time()\nmodel.eval()\ny_test = []\ny_pred = []\nfor images, labels in data_loader['test']:\n    images = images.to(device)\n    labels = labels.to(device)\n    outputs = model(images)\n    _, predictions = outputs.max(1)\n    \n    y_test.append(labels.data.cpu().numpy())\n    y_pred.append(predictions.data.cpu().numpy())\n    \ny_test = np.concatenate(y_test)\ny_pred = np.concatenate(y_pred)\ntime_elapsed = time.time() - since\n\nprint('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n\nconfusion_mtx = confusion_matrix(y_test, y_pred)\n# plot the confusion matrix\nplot_labels = ['COVID', 'Lung_Opacity', 'Normal', 'Pneunomia', 'Tuberculosis']\n\nplot_confusion_matrix(confusion_mtx, plot_labels)\nreport = classification_report(y_test, y_pred, digits=5)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T11:49:39.894545Z","iopub.execute_input":"2022-01-17T11:49:39.895269Z","iopub.status.idle":"2022-01-17T11:50:28.386848Z","shell.execute_reply.started":"2022-01-17T11:49:39.895233Z","shell.execute_reply":"2022-01-17T11:50:28.386073Z"},"trusted":true},"execution_count":null,"outputs":[]}]}